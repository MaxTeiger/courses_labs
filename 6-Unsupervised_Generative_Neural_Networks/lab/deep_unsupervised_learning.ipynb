{"metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.5.2"}}, "nbformat": 4, "nbformat_minor": 0, "cells": [{"cell_type": "code", "execution_count": 1, "metadata": {"collapsed": false}, "outputs": [], "source": ["import os\n", "from os import path\n", "from urllib.request import urlretrieve\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "from keras.datasets import fashion_mnist"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## I - Load and preprocess data"]}, {"cell_type": "code", "execution_count": 2, "metadata": {"collapsed": false}, "outputs": [], "source": ["(X_tr, y_tr), (X_te, y_te) = fashion_mnist.load_data()\n", "labels = [\n", "    \"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"\n", "]"]}, {"cell_type": "code", "execution_count": 3, "metadata": {"collapsed": false}, "outputs": [], "source": ["plt.figure(figsize=(10, 2))\n", "for i in range(0, 5):\n", "    index = np.random.randint(0, X_tr.shape[0])\n", "    plt.subplot(1, 5, i + 1)\n", "    plt.imshow(X_tr[index], cmap=\"gray\")\n", "    plt.title(labels[y_tr[index]])\n", "    plt.axis(\"off\")\n", "plt.show()"]}, {"cell_type": "code", "execution_count": 4, "metadata": {"collapsed": false}, "outputs": [], "source": ["def min_max_scaling(X):\n", "    minx, maxx = np.min(X, axis=0), np.max(X, axis=0)\n", "    return (X - minx) / (maxx - minx)"]}, {"cell_type": "code", "execution_count": 5, "metadata": {"collapsed": false}, "outputs": [], "source": ["X_tr, X_te = min_max_scaling(X_tr), min_max_scaling(X_te)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## II - Simple Autoencoder"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We are going to start in this part by defining a simple autoencoder:\n", "- the encoder has two Dense layers projecting into a latent dimension of fixed size (here we are going to choose latent_dim=2 for simplicity)\n", "- the decoder has also two Denser layers and tries to recontruct the original images"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<img src=\"../images/autoencoder.png\" width=\"500px\" />"]}, {"cell_type": "code", "execution_count": 6, "metadata": {"collapsed": false}, "outputs": [], "source": ["from keras.layers import Input, Dense\n", "from keras import Model\n", "\n", "class Autoencoder():\n", "    def __init__(self, X_tr, X_te, y_tr, y_te, labels, latent_dim=2, intermediate_dim=256, flatten=True):\n", "        # Data\n", "        if flatten:\n", "            self.X_tr = self.flatten_image(X_tr)\n", "            self.X_te = self.flatten_image(X_te)\n", "        else:\n", "            self.X_tr = X_tr\n", "            self.X_te = X_te\n", "        self.y_tr = y_tr\n", "        self.y_te = y_te\n", "        self.labels = labels\n", "        # Hyperparameters\n", "        self.original_dim = self.X_tr.shape[1]\n", "        self.intermediate_dim = intermediate_dim\n", "        self.latent_dim = latent_dim\n", "        # Models\n", "        self.encoder = None\n", "        self.decoder = None\n", "        self.model = None\n", "        \n", "    def flatten_image(self, X):\n", "        return X.reshape((X.shape[0], np.prod(X.shape[1:])))\n", "    \n", "    \"\"\"\n", "    Two Dense layers with relu activation\n", "    They respectively project into intermediate_dim and latent_dim dimensions\n", "    \"\"\"\n", "    def design_and_compile_encoder(self):\n", "        # TODO:\n", "        x = None\n", "        hidden = None\n", "        latent = None\n", "        if all([x, latent]):\n", "            return Model(\n", "                inputs=x, \n", "                outputs=latent, \n", "                name=\"mlp_encoder\"\n", "            )\n", "    \n", "    \"\"\"\n", "    Two Dense layers, the first has a relu activation and the last a sigmoid activation\n", "    Sigmoid activation can indeed be used in this case because our images have been min-max scaled previously\n", "    They respectively project into intermediate_dim and latent_dim dimensions\n", "    \"\"\"\n", "    def design_and_compile_decoder(self):   \n", "        # TODO:\n", "        latent = None\n", "        hidden = None\n", "        x = None\n", "        if all([latent, hidden]):\n", "            return Model(\n", "                inputs=latent, \n", "                outputs=x,\n", "                name=\"mlp_decoder\"\n", "            )\n", "    \n", "    \"\"\"\n", "    Define and compile the encoder/decoder models by calling the previous methods\n", "    Store them into self.encoder and self.decoder\n", "    You can now define your final model in self.model\n", "    \"\"\"\n", "    def design_and_compile_full_model(self):\n", "        # TODO:\n", "        self.encoder = None\n", "        self.decoder = None\n", "        \n", "        x = None\n", "        z = None\n", "        x_decoded = None\n", "        if all([x, x_decoded]):\n", "            self.model = Model(x, x_decoded)\n", "            self.model.compile(optimizer='adam', loss='mse')\n", "        \n", "    def model_summary(self):\n", "        if self.model is not None:\n", "            self.model.summary()\n", "        \n", "    def train(self, epochs=5, batch_size=100):\n", "        if self.model is None:\n", "            print(\"The model has not been designed yet!\")\n", "            return None\n", "            self.model.fit(\n", "                self.X_tr, self.X_tr,\n", "                epochs=epochs, batch_size=batch_size,\n", "                validation_data=(self.X_te, self.X_te)\n", "            )\n", "        \n", "    def plot_x_test_decoded_i(self, index):\n", "        if self.model is None:\n", "            print(\"The model has not been trained yet!\")\n", "            return None\n", "        plt.subplot(1, 2, 1)\n", "        plt.imshow(self.X_te[index].reshape(28, 28), cmap=plt.cm.gray)\n", "        plt.title(\"Real image\")\n", "        z = self.encoder.predict(np.expand_dims(self.X_te[index], axis=0))\n", "        decoded_image = self.decoder.predict(z)\n", "        plt.subplot(1, 2, 2)\n", "        plt.imshow(decoded_image.reshape(28, 28), cmap=plt.cm.gray)\n", "        plt.title(\"Reconstructed image\")\n", "        plt.axis('off');\n", "        \n", "    def plot_latent_space(self):\n", "        if self.model is None:\n", "            print(\"The model has not been trained yet!\")\n", "            return None\n", "        Z_te = self.encoder.predict(self.X_te, batch_size=100)\n", "        if isinstance(Z_te, list):\n", "            Z_te = Z_te[0]\n", "        plt.figure(figsize=(7, 6))\n", "        plt.scatter(Z_te[:, 0], Z_te[:, 1], c=self.y_te,\n", "                    cmap=plt.cm.tab10)\n", "        cb = plt.colorbar()\n", "        cb.set_ticks(list(range(len(self.labels))))\n", "        cb.set_ticklabels(self.labels)\n", "        cb.update_ticks()\n", "        plt.show()"]}, {"cell_type": "code", "execution_count": 7, "metadata": {"collapsed": false}, "outputs": [], "source": ["ae = Autoencoder(X_tr, X_te, y_tr, y_te, labels)\n", "ae.design_and_compile_full_model()\n", "ae.model_summary()\n", "ae.train(epochs=2)"]}, {"cell_type": "code", "execution_count": 8, "metadata": {"collapsed": false}, "outputs": [], "source": ["index = np.random.randint(0, ae.X_te.shape[0])\n", "\n", "ae.plot_x_test_decoded_i(index)"]}, {"cell_type": "code", "execution_count": 9, "metadata": {"collapsed": false}, "outputs": [], "source": ["ae.plot_latent_space()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## III - Fully Connected VAE"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In this part we are going to improve our simple autoencoder model by adding a gaussian noise in the latent representation\n", "\n", "The objective is to estimate both $q_{\\phi}(z | x)$ and $p_{\\theta}(x | z)$"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<img src=\"../images/vae_horiz.png\" width=\"700px\" />"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We can use the reparametrization trick to ensure that our samples are deterministically dependent on the parameters of the distribution\n", "\n", "Instead of sampling $z$ as below:\n", "$$ z \\sim \\mathcal{N}(\\mu(x), \\sigma(x)) $$\n", "\n", "We can do the following:\n", "$$ z = \\mu(x) + \\sigma(x) \\cdot \\epsilon$$\n", "with:\n", "$$ \\epsilon \\sim \\mathcal{N}(0, 1) $$\n", "\n", "In practice the encoder actually parametrizes $log(\\sigma^2(x)$ and not solely $\\sigma(x)$<br/>\n", "We take the exponential of $log(\\sigma^2_z(x)$ afterwards in the sampler layer, which ensures the positivity of the final $\\sigma$ that we are trying to learn"]}, {"cell_type": "code", "execution_count": 10, "metadata": {"collapsed": false}, "outputs": [], "source": ["from keras.layers import Lambda\n", "from keras import backend as K\n", "from keras import metrics\n", "\n", "class VariationalAutoencoder(Autoencoder):\n", "    def __init__(self, X_tr, X_te, y_tr, y_te, labels, latent_dim=2, intermediate_dim=256, flatten=True):\n", "        # Autoencoder class initialization\n", "        super(VariationalAutoencoder, self).__init__(\n", "            X_tr, X_te, y_tr, y_te, labels, latent_dim, intermediate_dim, flatten\n", "        )\n", "        # Models\n", "        self.sampler = None\n", "    \n", "    \"\"\"\n", "    The first Dense layer is identical to the standard autoencoder\n", "    However, it is now mandatory to have two parallel Dense layers projecting into self.latent_dim\n", "    They are respectively estimating z_mean and z_log_var\n", "    \"\"\"\n", "    def design_and_compile_encoder(self):\n", "        #\u00a0TODO:\n", "        x = None\n", "        hidden = None\n", "        z_mean = None\n", "        z_log_var = None\n", "        if all([x, z_mean, z_log_var]):\n", "            return Model(\n", "                inputs=x, \n", "                outputs=[z_mean, z_log_var], \n", "                name=\"mlp_encoder\"\n", "            )\n", "    \n", "    \"\"\"\n", "    Now we can use the estimated z_mean and z_log_var to sample z using a gaussian distribution\n", "    Define your inputs, wrap the sampling function in a Lambda layer, \n", "    and return a Model Keras Object that outputs the stochastic latent variable z\n", "    \"\"\"\n", "    def design_and_compile_sampler(self):\n", "        def _sampling(inputs):\n", "            z_mean, z_log_var = inputs\n", "            batch_size = K.shape(z_mean)[0]\n", "            epsilon = K.random_normal(shape=(batch_size, self.latent_dim),\n", "                                      mean=0., stddev=1.)\n", "            return z_mean + K.exp(z_log_var / 2) * epsilon\n", "    \n", "        # TODO:\n", "        z_mean = None\n", "        z_log_var = None\n", "        z = None\n", "        if all([z_mean, z_log_var, z]):\n", "            return Model(\n", "                inputs=[z_mean, z_log_var], \n", "                outputs=z,\n", "                name=\"mlp_sampler\"\n", "            )\n", "    \n", "    \"\"\"\n", "    The decoder is actually the same as the previous part in the standard autoencoder model\n", "    \"\"\"\n", "    def design_and_compile_decoder(self):\n", "        # TODO:\n", "        latent = None\n", "        hidden = None\n", "        x = None\n", "        if all([latent, x]):\n", "            return Model(\n", "                inputs=latent, \n", "                outputs=x, \n", "                name=\"mlp_decoder\"\n", "            )\n", "    \n", "    \"\"\"\n", "    Now you can use the three models that you have defined and compiled, \n", "    store them into self.encoder, self.sampler and self.decoder\n", "    Your final model will be defined in self.model afterward\n", "    The used loss function is the negative ELBO\n", "    \"\"\"\n", "    def design_and_compile_full_model(self):\n", "        # TODO:\n", "        self.encoder = None\n", "        self.sampler = None\n", "        self.decoder = None\n", "        \n", "        x = None\n", "        z_mean, z_log_var = None, None\n", "        z = None\n", "        x_decoded_mean = None\n", "        \n", "        if all([x, x_decoded_mean]):\n", "            self.model = Model(x, x_decoded_mean)\n", "\n", "            xent_loss = self.original_dim * metrics.binary_crossentropy(\n", "                K.flatten(x), K.flatten(x_decoded_mean)\n", "            )\n", "            kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n", "            vae_loss = K.mean(xent_loss + kl_loss)\n", "\n", "            self.model.add_loss(vae_loss)\n", "            self.model.compile(optimizer='adam')\n", "        \n", "    def train(self, epochs=5, batch_size=100):\n", "        if self.model is None:\n", "            print(\"The model has not been designed yet!\")\n", "            return None\n", "        self.model.fit(\n", "            self.X_tr, \n", "            epochs=epochs, batch_size=batch_size,\n", "            validation_data=(self.X_te, None)\n", "        )\n", "        \n", "    def plot_x_test_decoded_i(self, index):\n", "        if self.model is None:\n", "            print(\"The model has not been trained yet!\")\n", "            return None\n", "        plt.subplot(1, 2, 1)\n", "        plt.imshow(self.X_te[index].reshape(28, 28), cmap=plt.cm.gray)\n", "        plt.title(\"Real image\")\n", "        z_mean, z_log_var = self.encoder.predict(np.expand_dims(self.X_te[index], axis=0))\n", "        z = self.sampler.predict([z_mean, z_log_var])\n", "        decoded_image = self.decoder.predict(z)\n", "        plt.subplot(1, 2, 2)\n", "        plt.imshow(decoded_image.reshape(28, 28), cmap=plt.cm.gray)\n", "        plt.title(\"Reconstructed image\")\n", "        plt.axis('off');\n", "        \n", "    def plot_sampled_prediction(self):\n", "        if self.model is None:\n", "            print(\"The model has not been trained yet!\")\n", "            return None\n", "        random_z_from_prior = np.random.normal(size=(1, self.latent_dim))\n", "        generated = self.decoder.predict(random_z_from_prior)\n", "        plt.imshow(generated.reshape(28, 28), cmap=plt.cm.gray)\n", "        plt.axis('off');"]}, {"cell_type": "code", "execution_count": 11, "metadata": {"collapsed": false}, "outputs": [], "source": ["vae = VariationalAutoencoder(X_tr, X_te, y_tr, y_te, labels)\n", "vae.design_and_compile_full_model()\n", "vae.model_summary()\n", "vae.train(epochs=2)"]}, {"cell_type": "code", "execution_count": 12, "metadata": {"collapsed": false}, "outputs": [], "source": ["vae.plot_sampled_prediction()"]}, {"cell_type": "code", "execution_count": 13, "metadata": {"collapsed": false}, "outputs": [], "source": ["index = np.random.randint(0, vae.X_te.shape[0])\n", "\n", "vae.plot_x_test_decoded_i(index)"]}, {"cell_type": "code", "execution_count": 14, "metadata": {"collapsed": false}, "outputs": [], "source": ["vae.plot_latent_space()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## IV - Convolutional VAE"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In this final part, we are going to enrich the previous encoder and decoder with convolutional layers\n", "\n", "This allows us not to destroy the precious spatial representation in our images and extract local patterns that can be encoded"]}, {"cell_type": "code", "execution_count": 15, "metadata": {"collapsed": false}, "outputs": [], "source": ["from keras.layers import Flatten, Conv2D, BatchNormalization, Reshape, Conv2DTranspose\n", "\n", "class ConvolutionalVariationalAutoencoder(VariationalAutoencoder):\n", "    def __init__(self, X_tr, X_te, y_tr, y_te, labels, \n", "                 latent_dim=2, intermediate_dim=128, \n", "                 filters=32, kernel_size=3, spatial_size=7,\n", "                 flatten=False):\n", "        X_tr = np.expand_dims(X_tr, axis=-1)\n", "        X_te = np.expand_dims(X_te, axis=-1)\n", "        # VAE class initialization\n", "        super(ConvolutionalVariationalAutoencoder, self).__init__(\n", "            X_tr, X_te, y_tr, y_te, labels, latent_dim, intermediate_dim, flatten\n", "        )\n", "        # Hyperparameters\n", "        self.filters = filters\n", "        self.kernel_size = kernel_size\n", "        self.spatial_size = spatial_size\n", "        # Models\n", "        self.sampler = None\n", "    \n", "    \"\"\"\n", "    Use series of Conv2D layers with strides and batch normalization, and then continue with a Flatten layer\n", "    Add Dense layers afterwards to estimate z_mean and z_log_var\n", "    \"\"\"\n", "    def design_and_compile_encoder(self):\n", "        # TODO:\n", "        x = None\n", "        x_conv = None\n", "        x_flat = None\n", "        hidden = None\n", "        z_mean = None\n", "        z_log_var = None\n", "        if all([x, z_mean, z_log_var]):\n", "            return Model(\n", "                inputs=x, \n", "                outputs=[z_mean, z_log_var], \n", "                name=\"convolutional_encoder\"\n", "            )\n", "    \n", "    \"\"\"\n", "    Here we need a transformation going in the opposite direction of a normal Conv2D layer: Conv2DTranspose\n", "    It starts from the latent space to upsample to the image original dimension\n", "    Start with two Dense layers into a hidden dimension of (self.filters * self.spatial_size * self.spatial_size),\n", "    then use a Reshape layer to convert it to a 3D tensor: it will be your starting point for deconvolution layers\n", "    You can now use series of Conv2DTranspose layers with strides and batch normalization\n", "    Conclude your model with a standard Conv2D layer with sigmoid activation, and make sure you ends up with \n", "    the same dimensions as your original image\n", "    \"\"\"\n", "    def design_and_compile_decoder(self):\n", "        decoder_input = None\n", "        x = None\n", "        if all([decoder_input, x]):\n", "            return Model(decoder_input, x, name='convolutional_decoder')"]}, {"cell_type": "code", "execution_count": 16, "metadata": {"collapsed": false}, "outputs": [], "source": ["cvae = ConvolutionalVariationalAutoencoder(X_tr, X_te, y_tr, y_te, labels)\n", "cvae.design_and_compile_full_model()\n", "cvae.model_summary()\n", "cvae.train(epochs=2)"]}, {"cell_type": "code", "execution_count": 17, "metadata": {"collapsed": false}, "outputs": [], "source": ["cvae.plot_sampled_prediction()"]}, {"cell_type": "code", "execution_count": 18, "metadata": {"collapsed": false}, "outputs": [], "source": ["index = np.random.randint(0, cvae.X_te.shape[0])\n", "\n", "cvae.plot_x_test_decoded_i(index)"]}, {"cell_type": "code", "execution_count": 19, "metadata": {"collapsed": false}, "outputs": [], "source": ["cvae.plot_latent_space()"]}]}