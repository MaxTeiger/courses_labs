{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an introduction to basic sequence-to-sequence learning using a Long short term memory (LSTM) module.\n",
    "\n",
    "Given a string of characters representing a math problem \"3141+42\" we would like to generate a string of characters representing the correct solution: \"3183\". Our network will learn how to do basic mathematical operations.\n",
    "\n",
    "The important part is that we will not first use our human intelligence to break the string up into integers and a mathematical operator. We want the computer to figure all that out by itself.\n",
    "\n",
    "Each math problem is an input sequence: a list of {0,...,9} integers and math operation symbols\n",
    "The result of the operation (\"$3141+42$\" $\\rightarrow$ \"$3183$\"</span>) is the sequence to decode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**math_operators** is the set of $5$ operations we are going to use to build are input sequences.<br/>\n",
    "The math_expressions_generation function uses them to generate a large set of examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def math_expressions_generation(n_samples=1000, n_digits=3, invert=True):\n",
    "    X, Y = [], []\n",
    "    math_operators = {\n",
    "        '+': operator.add, \n",
    "        '-': operator.sub,\n",
    "        '*': operator.mul,\n",
    "        '/': operator.truediv,\n",
    "        '%': operator.mod\n",
    "    }\n",
    "    for i in range(n_samples):\n",
    "        a, b = np.random.randint(1, 10**n_digits, size=2)\n",
    "        op = np.random.choice(list(math_operators.keys()))\n",
    "        res = math_operators[op](a, b)\n",
    "        x = \"\".join([str(elem) for elem in (a, op, b)])\n",
    "        if invert is True:\n",
    "            x = x[::-1]\n",
    "        y = \"{:.5f}\".format(res) if isinstance(res, float) else str(res)\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = math_expressions_generation(n_samples=int(1e5), n_digits=3, invert=True)\n",
    "for X_i, y_i in list(zip(X, y))[:20]:\n",
    "    print(X_i[::-1], '=', y_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I - Sequence to sequence model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Seq2Seq architecture\n",
    "Two LSTMs: an encoder and a decoder\n",
    "\n",
    "<img src=\"../images/teacher_forcing_train.png\" style=\"width: 600px;\" />\n",
    "\n",
    "## Training with teacher forcing\n",
    "   - Build the Seq2Seq model for training\n",
    "   - Example:\n",
    "        - Input sequence \"94+8\" must is given to the encoding LSTM\n",
    "        - True previous answers \"1\", \"0\", \"2\" are given to the decoder LSTM\n",
    "            - Helps the decoder predict well the next token during training\n",
    "   - We advice to use Keras functional API here\n",
    "\n",
    "### encoder\n",
    "   - Define a layer **encoder_inputs** of shape $(None, $**self.encoder_vocabulary_size**$)$ \n",
    "   - Define the encoder LSTM layer before connecting it\n",
    "        - Call it **encoder_lstm**\n",
    "        - Use **return_state** param so it returns its last **state_h** and **state_c**\n",
    "           - Have to be passed to the decoder LSTM afterwards to connect the $2$ LSTMs\n",
    "   - Connect **encoder_lstm** to **encoder_inputs**\n",
    "       - Get **encoder_lstm**'s last **state_h** and **state_c** node variables\n",
    "           - Stack them in a **encoder_states** $=$ $[$**state_h**$,  $**state_c**$]$ variable\n",
    "      \n",
    "### decoder\n",
    "   - Define a layer **decoder_inputs** of shape $(None, $**self.decoder_vocabulary_size**$)$ \n",
    "   - Define the decoder LSTM layer before connecting it\n",
    "        - Call it **decoder_lstm**\n",
    "        - Pass encoder's last $[$**state_h**$, $**state_c**$]$ to decoder **initial_state** argument to connect the two LSTM\n",
    "        - Use the **return_sequences** param so the decoder returns all the $h_{t}^{dec}$\n",
    "            - We need them to compute the predictions using the $h_{t}^{dec}$\n",
    "        - Use the **return_state** param so the decoder also returns its last **state_h** and **state_c**\n",
    "            - We ignore those now but we will need them for inference\n",
    "   - Connect **decoder_lstm** to **decoder_inputs**\n",
    "       - Get the $h_{t}^{dec}$ hidden layers in a **decoder_all_hdec** node variable\n",
    "       - Ignore **decoder_lstm**'s last **state_h** and **state_c** returned\n",
    "\n",
    "### output\n",
    "   - At this point, all the $h_{t}^{dec}$ are in a **decoder_all_hdec** node\n",
    "      - Ready to be used to perform a token prediction for all timesteps\n",
    "   - Define a Dense layer. Call it **decoder_dense**\n",
    "       - Give it a softmax activation and **self.decoder_vocabulary_size** output dimensionality\n",
    "   - Connect **decoder_dense** to **decoder_all_hdec**\n",
    "     - Get the $\\hat{y}^t$ predictions in a **decoder_outputs** node variable\n",
    "     - Each $h_{t}^{dec}$ has been mapped to a $($**self.decoder_vocabulary_size**$,1)$ probability distribution over the next token\n",
    "   - **decoder_outputs** should be of shape $(batch,$ **self.max_decoder_sequence_length**$,$ **self.decoder_vocabulary_size**$)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference (testing time - no teacher forcing)\n",
    "\n",
    "   - We are going to see how to perform inference\n",
    "       - Decoding a new sequence with trained weights without using teacher forcing\n",
    "   - We won't provide the <...EOS> part of the sequences like during training\n",
    "   - Predictions have to be performed one step at a time\n",
    "   - At first we will use encoder's last state and GO token\n",
    "       - Produces the $1{st}$ decoder hidden layer  $h_{0}^{dec}$\n",
    "   - Secondly we will use $h_{0}^{dec}$ to predict $\\hat{y}^0$ token\n",
    "   - Thirdly we will use $h_{0}^{dec}$ and $\\hat{y}^0$ token\n",
    "       - Produces $h_{1}^{dec}$ then used to predict $\\hat{y}^1$ token\n",
    "   - etc.\n",
    "\n",
    "### Requirements\n",
    "\n",
    "   - To perform inference we are going to need an **inference encoder model**\n",
    "       - Takes in the input sequence and returns the last $h$ and $c$ state\n",
    "           - To be passed to the decoder\n",
    "   - To perform inference we also are going to need a **inference decoder model**\n",
    "       - Takes in the previous hidden state $h_{t-1}^{dec}$\n",
    "       - Takes in a token: GO or previous $\\hat{y}^{t-1}$\n",
    "       - Returns next $h_{t}^{dec}$ and $\\hat{y}^{t}$\n",
    "       - Iterates over these steps\n",
    "           - Until it produces the EOS token or decoded sequence is too long\n",
    "\n",
    "We are going to reuse layers and nodes from before:\n",
    "   - **encoder_inputs**, **encoder_states** and **decoder_all_hdec** nodes that are already connected\n",
    "   - **decoder_lstm**, **decoder_inputs** and **decoder_dense** layers\n",
    "\n",
    "### inference_encoder_model\n",
    "   - Use the class Model from keras.models\n",
    "   - Make the node **encoder_inputs** the model's input\n",
    "   - Make the node **encoder_states** the model's output\n",
    "\n",
    "### inference_decoder_model\n",
    "   - Define $2$ $Input$ keras.layers of dimensionality **latent_dim**\n",
    "       - **decoder_state_input_h** and **decoder_state_input_c**\n",
    "          - **decoder_model**'s last state\n",
    "          - To be given later to **inference_decoder_model**'s predict function\n",
    "          - Stack them in a **decoder_states_inputs** variable\n",
    "              - **decoder_states_inputs**$ = [$**decoder_state_input_h**$, $**decoder_state_input_c**$]$\n",
    "              \n",
    "   - Connect **decoder_lstm** to **decoder_inputs**\n",
    "       - While connecting use the argument **initial_state**$ = $**decoder_states_inputs**\n",
    "       - Get **decoder_all_hdec**, **decoder_state_h**, **decoder_state_c** from that connection\n",
    "          - **decoder_all_hdec** is all the $h_{t}^{dec}$ produced\n",
    "             - $1$ token at a time is given, thus **decoder_all_hdec** shape is $(1,$**latent_dim**$)$\n",
    "          - **decoder_state_h** is the last $h_{t}^{dec}$\n",
    "              - First part of **decoder_lstm**'s last state\n",
    "              - Will be **decoder_state_input_h** at next iteration\n",
    "          - **decoder_state_c**, is the last $c_{t}^{dec}$\n",
    "              - Second part of **decoder_lstm**'s last state\n",
    "              - Will be **decoder_state_input_c** at next iteration\n",
    "          - Stack **decoder_state_h** and **decoder_state_c** in a **decoder_states** variable\n",
    "              - **decoder_states**$ = [$**decoder_state_h**$, $**decoder_state_c**$]$\n",
    "          - **decoder_state_h** and **decoder_state_c** will be returned along with prediction $\\hat{y}^{t}$\n",
    "          \n",
    "   - Connect **decoder_dense** layer from before to **decoder_all_hdec**\n",
    "       - Produces the distribution probability $\\hat{y}^t$ over the next token\n",
    "       - Get the $\\hat{y}^t$ prediction in a **decoder_outputs** node variable\n",
    "       \n",
    "   - At this point we have\n",
    "       - Next prediction **decoder_outputs**\n",
    "       - Last state **decoder_states**\n",
    "       \n",
    "   - We are ready to define the decoder_model\n",
    "       - Make $[$**decoder_inputs**$] + $**decoder_states_inputs** the model's inputs\n",
    "       - Make $[$**decoder_outputs**$] + $**decoder_states** the model's outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GO** is the character (\"=\") that marks the beginning of decoding for the decoder LSTM<br/>\n",
    "**EOS** is the character (\"\\n\") that marks the end of sequence to decode for the decoder LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class Seq2seq():\n",
    "    def __init__(self, X, y):\n",
    "        # Special tokens\n",
    "        self.GO = '='\n",
    "        self.EOS = '\\n'\n",
    "        # Dataset properties\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.X_tr = None\n",
    "        self.X_val = None\n",
    "        self.y_tr = None\n",
    "        self.y_val = None\n",
    "        self.n = None\n",
    "        self.encoder_char_index = None\n",
    "        self.encoder_char_index_inversed = None\n",
    "        self.decoder_char_index = None\n",
    "        self.decoder_char_index_inversed = None\n",
    "        self.encoder_vocabulary_size = None\n",
    "        self.decoder_vocabulary_size = None\n",
    "        self.max_encoder_sequence_length = None\n",
    "        self.max_decoder_sequence_length = None\n",
    "        # Preprocessed data\n",
    "        self.encoder_input_data_tr = None\n",
    "        self.encoder_input_data_val = None\n",
    "        self.decoder_input_data_tr = None\n",
    "        self.decoder_input_data_val = None\n",
    "        self.decoder_target_data_tr = None\n",
    "        self.decoder_target_data_val = None\n",
    "        # Model properties\n",
    "        self.training_model = None\n",
    "        self.inference_encoder_model = None\n",
    "        self.inference_decoder_model = None\n",
    "        self.batch_size = None\n",
    "        self.epochs = None\n",
    "        self.latent_dim = None\n",
    "        # Model layers and states that we want to keep in memory between training and inference\n",
    "        ## Encoder\n",
    "        self.encoder_inputs = None\n",
    "        self.encoder_states = None\n",
    "        ## Decoder\n",
    "        self.decoder_inputs = None\n",
    "        self.decoder_lstm = None\n",
    "        self.decoder_all_hdec = None\n",
    "        self.decoder_dense = None\n",
    "        # Dataset construction call\n",
    "        self.load_and_preprocess_data(X, y)\n",
    "        self.construct_dataset()\n",
    "        \n",
    "    def load_and_preprocess_data(self, X, y):\n",
    "        self.X = list(X)\n",
    "        self.y = list(map(lambda token: self.GO + token + self.EOS, y))\n",
    "        self.n = len(self.X)\n",
    "        encoder_characters = sorted(list(set(\"\".join(self.X))))\n",
    "        decoder_characters = sorted(list(set(\"\".join(self.y))))\n",
    "        self.encoder_char_index = dict((c, i) for i, c in enumerate(encoder_characters))\n",
    "        self.encoder_char_index_inversed = dict((i, c) for i, c in enumerate(encoder_characters))\n",
    "        self.decoder_char_index = dict((c, i) for i, c in enumerate(decoder_characters))\n",
    "        self.decoder_char_index_inversed = dict((i, c) for i, c in enumerate(decoder_characters))\n",
    "        self.encoder_vocabulary_size = len(self.encoder_char_index)\n",
    "        self.decoder_vocabulary_size = len(self.decoder_char_index)\n",
    "        self.max_encoder_sequence_length = max([len(sequence) for sequence in self.X])\n",
    "        self.max_decoder_sequence_length = max([len(sequence) for sequence in self.y])\n",
    "        print('Number of samples:', self.n)\n",
    "        print('Number of unique encoder tokens:', self.encoder_vocabulary_size)\n",
    "        print('Number of unique decoder tokens:', self.decoder_vocabulary_size)\n",
    "        print('Max sequence length for encoding:', self.max_encoder_sequence_length)\n",
    "        print('Max sequence length for decoding:', self.max_decoder_sequence_length)\n",
    "        (self.X_tr, self.X_val, \n",
    "         self.y_tr, self.y_val) = train_test_split(\n",
    "            self.X, \n",
    "            self.y,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "    def construct_dataset(self):\n",
    "        encoder_input_data = np.zeros(\n",
    "            (self.n, self.max_encoder_sequence_length, self.encoder_vocabulary_size),\n",
    "            dtype='float32')\n",
    "        decoder_input_data = np.zeros(\n",
    "            (self.n, self.decoder_vocabulary_size, self.decoder_vocabulary_size),\n",
    "            dtype='float32')\n",
    "        decoder_target_data = np.zeros(\n",
    "            (self.n, self.decoder_vocabulary_size, self.decoder_vocabulary_size),\n",
    "            dtype='float32')\n",
    "        for i, (X_i, y_i) in enumerate(zip(self.X, self.y)):\n",
    "            for t, char in enumerate(X_i):\n",
    "                encoder_input_data[i, t, self.encoder_char_index[char]] = 1.\n",
    "            for t, char in enumerate(y_i):\n",
    "                decoder_input_data[i, t, self.decoder_char_index[char]] = 1.\n",
    "                if t > 0:\n",
    "                    decoder_target_data[i, t - 1, self.decoder_char_index[char]] = 1.\n",
    "        (self.encoder_input_data_tr, self.encoder_input_data_val, \n",
    "         self.decoder_input_data_tr, self.decoder_input_data_val,\n",
    "         self.decoder_target_data_tr, self.decoder_target_data_val) = train_test_split(\n",
    "            encoder_input_data, \n",
    "            decoder_input_data, \n",
    "            decoder_target_data,\n",
    "            random_state=42\n",
    "        )\n",
    "    \n",
    "    \"\"\"\n",
    "    ENCODER LAYERS:\n",
    "        - define a Input Keras object in self.encoder_inputs\n",
    "        - apply a LSTM layer on self.encoder_inputs to get the last state_h and state_c\n",
    "        - stack those states into an array self.encoder_states\n",
    "    DECODER LAYERS:\n",
    "        - define an Input Keras object in self.decoder_inputs\n",
    "        - define a LSTM layer in self.decoder_lstm, make sure you set return_sequences=True\n",
    "        to be able to return all hidden states\n",
    "        - apply this LSTM layer on self.decoder_inputs with the states initialized with self.encoder_states\n",
    "        and output all the hidden states in self.decoder_all_hdec\n",
    "        - define a Dense layer in self.decoder_dense with a softmax activation, and output the results \n",
    "        in decoder_outputs using self.decoder_all_hdec as inputs\n",
    "    MODEL DEFINITION:\n",
    "        - now you can build your global Model:\n",
    "        Model([self.encoder_inputs, self.decoder_inputs], decoder_outputs)\n",
    "    \"\"\"\n",
    "    def design_and_compile_training_model(self, batch_size=64, latent_dim=256):\n",
    "        # Hyperparameters\n",
    "        self.batch_size = batch_size\n",
    "        self.latent_dim = latent_dim\n",
    "        # Encoder layers\n",
    "        # TODO:\n",
    "        self.encoder_inputs = None\n",
    "        self.encoder_states = None\n",
    "        # Decoder layers\n",
    "        # TODO:\n",
    "        self.decoder_inputs = None\n",
    "        self.decoder_lstm = None\n",
    "        self.decoder_all_hdec = None\n",
    "        self.decoder_dense = None\n",
    "        decoder_outputs = None\n",
    "        # Model definition and compilation\n",
    "        if all(tensor is not None for tensor in [self.encoder_inputs, self.decoder_inputs, decoder_outputs]):\n",
    "            self.training_model = Model([self.encoder_inputs, self.decoder_inputs], decoder_outputs)\n",
    "            self.training_model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "            self.training_model.summary()\n",
    "        else:\n",
    "            print(\"Inputs and outputs of the model are not correctly defined!\")\n",
    "        \n",
    "    def train(self, epochs=15):\n",
    "        # Hyperparameters\n",
    "        self.epochs = epochs\n",
    "        # Model actual training\n",
    "        if self.training_model is not None:\n",
    "            self.training_model.fit(\n",
    "                [self.encoder_input_data_tr, self.decoder_input_data_tr], self.decoder_target_data_tr,\n",
    "                batch_size=self.batch_size,\n",
    "                epochs=self.epochs,\n",
    "                validation_data=(\n",
    "                    [self.encoder_input_data_val, self.decoder_input_data_val], self.decoder_target_data_val\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    \"\"\"\n",
    "    ENCODER MODEL:\n",
    "        - create a Keras Model self.inference_encoder_model \n",
    "        with self.encoder_inputs as inputs and self.encoder_states as output\n",
    "    DECODER MODEL:\n",
    "        - define two Input Keras objects: one for the h_state and the other for the c_state, then stack\n",
    "        them into a decoder_states_inputs array\n",
    "        - reuse the already trained self.decoder_lstm layer with self.decoder_inputs as input\n",
    "        and decoder_states_inputs as initial_state\n",
    "            - you should get three outputs: decoder_all_hdec, decoder_state_h and decoder_state_c\n",
    "        - again, stack the outputed decoder_state_h and decoder_state_c into a decoder_states array\n",
    "        - now reuse the already trained self.decoder_dense layer with decoder_all_hdec as input,\n",
    "        and store the output into decoder_outputs\n",
    "        - you can finally create a Keras Model self.inference_decoder_model\n",
    "        with [self.decoder_inputs] + decoder_states_inputs as inputs \n",
    "        and [decoder_outputs] + decoder_states as output\n",
    "    \"\"\"\n",
    "    def design_inference_model(self):\n",
    "        if self.training_model is None:\n",
    "            print(\"No training model has been defined yet!\")\n",
    "            return None\n",
    "        # Encoder model\n",
    "        # TODO:\n",
    "        self.inference_encoder_model = None\n",
    "        # Decoder model\n",
    "        ## Inputs: latent variables from the encoder\n",
    "        # TODO:\n",
    "        decoder_states_inputs = None\n",
    "        ## Decoding using the LSTM trained layer from the decoder\n",
    "        # TODO:\n",
    "        decoder_states = None\n",
    "        ## Get outputs using the Dense trained layer from the decoder\n",
    "        # TODO:\n",
    "        decoder_outputs = None\n",
    "        ## Define the whole decoding model\n",
    "        # TODO:\n",
    "        self.inference_decoder_model = None\n",
    "        \n",
    "    def decode_sequence(self, input_sequence):\n",
    "        if self.inference_encoder_model is None or self.inference_decoder_model is None:\n",
    "            print(\"Inference models have not been designed yet!\")\n",
    "            return None\n",
    "        states_value = self.inference_encoder_model.predict(input_sequence)\n",
    "        target_sequence = np.zeros((1, 1, self.decoder_vocabulary_size))\n",
    "        target_sequence[0, 0, self.decoder_char_index[self.GO]] = 1.\n",
    "        decoded_sentence = ''\n",
    "        while len(decoded_sentence) <= self.max_decoder_sequence_length:\n",
    "            output_tokens, h, c = self.inference_decoder_model.predict(\n",
    "                [target_sequence] + states_value\n",
    "            )\n",
    "            states_value = [h, c]\n",
    "            sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "            sampled_char = self.decoder_char_index_inversed[sampled_token_index]\n",
    "            decoded_sentence += sampled_char\n",
    "            if sampled_char == self.EOS:\n",
    "                break\n",
    "            target_sequence = np.zeros((1, 1, self.decoder_vocabulary_size))\n",
    "            target_sequence[0, 0, sampled_token_index] = 1.\n",
    "        return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq = Seq2seq(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq.design_and_compile_training_model(latent_dim=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq.train(epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq.design_inference_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if seq2seq.inference_encoder_model is not None and seq2seq.inference_decoder_model is not None:\n",
    "    for sequence_index in range(10):\n",
    "        input_sequence = seq2seq.encoder_input_data_val[sequence_index: sequence_index + 1]\n",
    "        decoded_sentence = seq2seq.decode_sequence(input_sequence)\n",
    "        print('-')\n",
    "        raw_input_sequence = \"\".join(\n",
    "            [seq2seq.encoder_char_index_inversed[np.argmax(token)] for token in np.squeeze(input_sequence)][::-1]\n",
    "        )\n",
    "        print('Input sentence:', seq2seq.X_val[sequence_index][::-1])\n",
    "        print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "\n",
    "- 1) Explain the interest in using teacher forcing during training. What is specific about this process ?\n",
    "- 2) Describe step by step how the encoder-decoder couple works in this case (~ 5-10 lines)\n",
    "- 3) Why is it mandatory to have different implementations between training and inference? Why do we need different models ? (~ 3-6 lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II - Sequence to sequence model with attention mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to improve your previous model from part I with attention mechanism<br/>\n",
    "Note that it will be a bit different from the implementation seen in the course for practical reasons<br/>\n",
    "In this part, you will concatenate the attention weights with the hidden decoder states after the decoding pass, and feed the result to final Dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation, dot, concatenate, TimeDistributed\n",
    "\n",
    "class Seq2seqAttention(Seq2seq):\n",
    "    def __init__(self, X, y):\n",
    "        # Attention layers hyperparameters\n",
    "        self.latent_attention_dim = 64\n",
    "        # All hidden states from the encoder that must now be stored\n",
    "        self.encoder_outputs = None\n",
    "        # Attention layers and states\n",
    "        self.dense_tanh = None\n",
    "        self.dense_final = None\n",
    "        # Seq2Seq class initialization\n",
    "        super(Seq2seqAttention, self).__init__(X, y)\n",
    "    \n",
    "    \"\"\"\n",
    "    ENCODER LAYERS:\n",
    "        - define a Input Keras object in self.encoder_inputs       \n",
    "        - apply a LSTM layer with return_sequences=True on self.encoder_inputs \n",
    "        to get (self.encoder_outputs, state_h, state_c)\n",
    "        - stack state_h and state_c into an array self.encoder_states\n",
    "    DECODER LAYERS:\n",
    "        - define an Input Keras object in self.decoder_inputs\n",
    "        - define a LSTM layer in self.decoder_lstm, make sure you set return_sequences=True\n",
    "        to be able to return all hidden states\n",
    "        - apply this LSTM layer on self.decoder_inputs with the states initialized with self.encoder_states\n",
    "        and output all the hidden states in self.decoder_all_hdec\n",
    "    ATTENTION LAYERS:\n",
    "        - apply a dot product between self.decoder_all_hdec and self.encoder_outputs along their last\n",
    "        dimension (the latent one), then a softmax activation, and store the result into attention\n",
    "        - compute the context tensor with a dot product between attention and self.encoder_outputs\n",
    "        - concatenate the result with self.decoder_all_hdec\n",
    "        - define the two final Dense layers: \n",
    "            - the first with tanh activation and self.latent_attention_dim size\n",
    "            - the second with softmax activation and self.decoder_vocabulary_size\n",
    "        - output the final result into attention_outputs\n",
    "    MODEL DEFINITION:\n",
    "        - now you can build your global Model:\n",
    "        Model([self.encoder_inputs, self.decoder_inputs], attention_outputs)\n",
    "    \"\"\"\n",
    "    def design_and_compile_training_model(self, batch_size=64, latent_dim=256, latent_attention_dim=64):\n",
    "        # Hyperparameters\n",
    "        self.batch_size = batch_size\n",
    "        self.latent_dim = latent_dim\n",
    "        self.latent_attention_dim = latent_attention_dim\n",
    "        # Encoder layers\n",
    "        # TODO:\n",
    "        self.encoder_inputs = None\n",
    "        self.encoder_states = None\n",
    "        self.encoder_outputs = None\n",
    "        # Decoder layers\n",
    "        # TODO:\n",
    "        self.decoder_inputs = None\n",
    "        self.decoder_lstm = None\n",
    "        self.decoder_all_hdec = None\n",
    "        # Attention layers\n",
    "        # TODO:\n",
    "        self.dense_tanh = None\n",
    "        self.dense_final = None\n",
    "        attention_outputs = None\n",
    "        # Model definition and compilation\n",
    "        if all(tensor is not None for tensor in [self.encoder_inputs, self.decoder_inputs, attention_outputs]):\n",
    "            self.training_model = Model([self.encoder_inputs, self.decoder_inputs], attention_outputs)\n",
    "            self.training_model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "            self.training_model.summary()\n",
    "        else:\n",
    "            print(\"Inputs and outputs of the model are not correctly defined!\")\n",
    "        \n",
    "    \"\"\"\n",
    "    ENCODER MODEL:\n",
    "        - create a Keras Model self.inference_encoder_model \n",
    "        with self.encoder_inputs as inputs and self.encoder_states as output\n",
    "    DECODER MODEL:\n",
    "        - define two Input Keras objects: one for the h_state and the other for the c_state, then stack\n",
    "        them into a decoder_states_inputs array\n",
    "        - reuse the already trained self.decoder_lstm layer with self.decoder_inputs as input\n",
    "        and decoder_states_inputs as initial_state\n",
    "            - you should get three outputs: decoder_all_hdec, decoder_state_h and decoder_state_c\n",
    "        - again, stack the outputed decoder_state_h and decoder_state_c into a decoder_states array        \n",
    "        - now apply a dot product between decoder_all_hdec and self.encoder_outputs along their last\n",
    "        dimension (the latent one), then a softmax activation: it is your attention tensor\n",
    "        - compute the context tensor with a dot product between the attention tensor and self.encoder_outputs\n",
    "        - concatenate the result with decoder_all_hdec\n",
    "        - reuse the two trained Denser layers and output the final result into attention_outputs\n",
    "        - you can finally create a Keras Model self.inference_decoder_model\n",
    "        with [self.decoder_inputs] + [self.decoder_inputs] + decoder_states_inputs as inputs \n",
    "        and [attention_outputs] + decoder_states as output\n",
    "    \"\"\"\n",
    "    def design_inference_model(self):\n",
    "        if self.training_model is None:\n",
    "            print(\"No training model has been defined yet!\")\n",
    "            return None\n",
    "        # Encoder model\n",
    "        # TODO:\n",
    "        self.inference_encoder_model = None\n",
    "        # Decoder model\n",
    "        ## Inputs: latent variables from the encoder\n",
    "        # TODO:\n",
    "        decoder_states_inputs = None\n",
    "        ## Decoding using the LSTM trained layer from the decoder\n",
    "        # TODO:\n",
    "        decoder_states = None\n",
    "        ## Get outputs using multiple dot products and softmax activation followed by the two trained Dense layers\n",
    "        # TODO:\n",
    "        attention_outputs = None\n",
    "        ## Define the whole decoding model\n",
    "        # TODO:\n",
    "        self.inference_decoder_model = None\n",
    "        \n",
    "    def decode_sequence(self, input_sequence):\n",
    "        if self.inference_encoder_model is None or self.inference_decoder_model is None:\n",
    "            print(\"Inference models have not been designed yet!\")\n",
    "            return None\n",
    "        states_value = self.inference_encoder_model.predict(input_sequence)\n",
    "        target_sequence = np.zeros((1, 1, self.decoder_vocabulary_size))\n",
    "        target_sequence[0, 0, self.decoder_char_index[self.GO]] = 1.\n",
    "        decoded_sentence = ''\n",
    "        while len(decoded_sentence) <= self.max_decoder_sequence_length:\n",
    "            output_tokens, h, c = self.inference_decoder_model.predict(\n",
    "                [input_sequence] + [target_sequence] + states_value\n",
    "            )\n",
    "            states_value = [h, c]\n",
    "            sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "            sampled_char = self.decoder_char_index_inversed[sampled_token_index]\n",
    "            decoded_sentence += sampled_char\n",
    "            if sampled_char == self.EOS:\n",
    "                break\n",
    "            target_sequence = np.zeros((1, 1, self.decoder_vocabulary_size))\n",
    "            target_sequence[0, 0, sampled_token_index] = 1.\n",
    "        return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq_attention = Seq2seqAttention(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq_attention.design_and_compile_training_model(latent_dim=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq_attention.train(epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq_attention.design_inference_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if seq2seq_attention.inference_encoder_model is not None and seq2seq_attention.inference_decoder_model is not None:\n",
    "    for sequence_index in range(10):\n",
    "        input_sequence = seq2seq_attention.encoder_input_data_val[sequence_index: sequence_index + 1]\n",
    "        decoded_sentence = seq2seq_attention.decode_sequence(input_sequence)\n",
    "        print('-')\n",
    "        raw_input_sequence = \"\".join(\n",
    "            [seq2seq_attention.encoder_char_index_inversed[np.argmax(token)] \n",
    "             for token in np.squeeze(input_sequence)][::-1]\n",
    "        )\n",
    "        print('Input sentence:', seq2seq_attention.X_val[sequence_index][::-1])\n",
    "        print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "\n",
    "- 1) Explain the main differences with the previous part, how does the attention mechanism work? (~ 5-10 lines)\n",
    "- 2) Compare the perfomances of your model at inference time with and without attention mechanism"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
